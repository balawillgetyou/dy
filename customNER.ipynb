{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe749af-7f07-4dec-86d2-8bb5970f8245",
   "metadata": {},
   "source": [
    "# Use case - jurisdiction of contracts:  \n",
    "It is common for parties to a contract to agree upfront where disputes, if any, will be resolved. How does one extract just such jurisdictions from a repository of contracts?  \n",
    "One way to do so is to treat jurisdiction as another entity and adapt a Named Entity Recognition (NER) token classifier for this task. This is the approach for the solution below.  \n",
    "Since a repo of contracts is hard to come by, reviews from a motorocyle hobby magazine have been used here as proxy data. The special tags used are for engine capacity, power and torque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e91e38f-7795-4fb0-a226-f9c2a22a926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q datasets transformers evaluate seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e28ab7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "from datasets import Dataset, Features, Value, ClassLabel, Sequence\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "485c85b0-1291-447d-a955-580b8b73df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tokens_with_entities(train_text: str):\n",
    "    raw_tokens = re.split(r\"\\s(?![^\\[]*\\])\", train_text)\n",
    "    entity_value_pattern = r\"\\[(?P<value>.+?)\\]\\((?P<entity>.+?)\\)\"\n",
    "    entity_value_pattern_compiled = re.compile(entity_value_pattern, flags=re.I|re.M)\n",
    "\n",
    "    tokens_with_entities = []\n",
    "\n",
    "    for raw_token in raw_tokens:\n",
    "        match = entity_value_pattern_compiled.match(raw_token)\n",
    "        if match:\n",
    "            raw_entity_name, raw_entity_value = match.group(\"entity\"), match.group(\"value\")\n",
    "\n",
    "            for i, raw_entity_token in enumerate(re.split(\"\\s\", raw_entity_value)):\n",
    "                entity_prefix = \"B\" if i == 0 else \"I\"\n",
    "                entity_name = f\"{entity_prefix}-{raw_entity_name}\"\n",
    "                tokens_with_entities.append((raw_entity_token, entity_name))\n",
    "        else:\n",
    "            tokens_with_entities.append((raw_token, \"O\"))\n",
    "\n",
    "    return tokens_with_entities\n",
    "\n",
    "\n",
    "class NERDataMaker:\n",
    "    def __init__(self, texts):\n",
    "        self.unique_entities = []\n",
    "        self.processed_texts = []\n",
    "\n",
    "        temp_processed_texts = []\n",
    "        for text in texts:\n",
    "            tokens_with_entities = get_tokens_with_entities(text)\n",
    "            for _, ent in tokens_with_entities:\n",
    "                if ent not in self.unique_entities:\n",
    "                    self.unique_entities.append(ent)\n",
    "            temp_processed_texts.append(tokens_with_entities)\n",
    "\n",
    "        self.unique_entities.sort(key=lambda ent: ent if ent != \"O\" else \"\")\n",
    "\n",
    "        for tokens_with_entities in temp_processed_texts:\n",
    "            self.processed_texts.append([(t, self.unique_entities.index(ent)) for t, ent in tokens_with_entities])\n",
    "\n",
    "    @property\n",
    "    def id2label(self):\n",
    "        return dict(enumerate(self.unique_entities))\n",
    "\n",
    "    @property\n",
    "    def label2id(self):\n",
    "        return {v:k for k, v in self.id2label.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.processed_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        def _process_tokens_for_one_text(id, tokens_with_encoded_entities):\n",
    "            ner_tags = []\n",
    "            tokens = []\n",
    "            for t, ent in tokens_with_encoded_entities:\n",
    "                ner_tags.append(ent)\n",
    "                tokens.append(t)\n",
    "\n",
    "            return {\n",
    "                \"id\": id,\n",
    "                \"ner_tags\": ner_tags,\n",
    "                \"tokens\": tokens\n",
    "            }\n",
    "\n",
    "        tokens_with_encoded_entities = self.processed_texts[idx]\n",
    "        if isinstance(idx, int):\n",
    "            return _process_tokens_for_one_text(idx, tokens_with_encoded_entities)\n",
    "        else:\n",
    "            return [_process_tokens_for_one_text(i+idx.start, tee) for i, tee in enumerate(tokens_with_encoded_entities)]\n",
    "\n",
    "    def as_hf_dataset(self, tokenizer):\n",
    "        def tokenize_and_align_labels(examples):\n",
    "            tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "            labels = []\n",
    "            for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "                word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "                previous_word_idx = None\n",
    "                label_ids = []\n",
    "                for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "                    if word_idx is None:\n",
    "                        label_ids.append(-100)\n",
    "                    elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                        label_ids.append(label[word_idx])\n",
    "                    else:\n",
    "                        label_ids.append(-100)\n",
    "                    previous_word_idx = word_idx\n",
    "                labels.append(label_ids)\n",
    "\n",
    "            tokenized_inputs[\"labels\"] = labels\n",
    "            return tokenized_inputs\n",
    "\n",
    "        ids, ner_tags, tokens = [], [], []\n",
    "        for i, pt in enumerate(self.processed_texts):\n",
    "            ids.append(i)\n",
    "            pt_tokens,pt_tags = list(zip(*pt))\n",
    "            ner_tags.append(pt_tags)\n",
    "            tokens.append(pt_tokens)\n",
    "        data = {\n",
    "            \"id\": ids,\n",
    "            \"ner_tags\": ner_tags,\n",
    "            \"tokens\": tokens\n",
    "        }\n",
    "        features = Features({\n",
    "            \"tokens\": Sequence(Value(\"string\")),\n",
    "            \"ner_tags\": Sequence(ClassLabel(names=dm.unique_entities)),\n",
    "            \"id\": Value(\"int32\")\n",
    "        })\n",
    "        ds = Dataset.from_dict(data, features)\n",
    "        tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)\n",
    "        return tokenized_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbe21153-18e5-46e4-9299-4c5d8ca7a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    prediction_out = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=prediction_out, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "def postprocess(test_ds):\n",
    "    logits, labels = trainer.predict(test_ds)[0:2]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    prediction_out = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return {'tokens': test_ds['tokens']}, {'true_labels': true_labels}, {'prediction_out':prediction_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e2a1a18-7640-4728-bebf-f9f9e1b3364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"\"\"\n",
    "The [286cc](capacity), 4 valve liquid-cooled engine architecture is the same as before, but the engine is now BS6 compliant. Power is now up by [0.6hp](power) for a total of [31.1 horsepower](power), although this is now produced 1,500rpm higher at 9,000rpm.\n",
    "Being a J-series model, the Hunter 350 gets the same [349cc](capacity), single-cylinder engine that powers the Classic and Meteor 350s. It puts out [20hp](power) and [27Nm](torque), which is adequate for a bike of this size, and comes paired with a 5-speed gearbox\"\n",
    "Powering the TVS Ronin is a [225.9cc](capacity), four-valve, single-cylinder engine that puts out [20.4hp](power) at 7,750rpm and [19.93Nm](torque) of torque at 3,750rpm.\n",
    "While the power and torque figures are exactly the same ([20hp](power) and [27Nm](torque)), RE says they have mapped the engine slightly differently.\n",
    "Power has gone up from [150hp](power) to [152hp](power) along with a shift in the redline from 10,000rpm to 11,000rpm. The engine also produces stronger bottom end torque and a wider as well as smoother torque curve.\n",
    "The in-house developed motor produces similar power figures to the Ola S1 Pro ([4.5kW](power) continuous/[8.5kW](power) peak), but it's the [72Nm](torque) torque figure that is unrivalled in the e-scooter space. \n",
    "The Bajaj Pulsar N160 is, essentially, the Pulsar N250 with a smaller displacement engine, a [164.82cc](capacity), air- and oil-cooled single, to be precise. It has a long-stroke configuration, with a simple two-valve head and makes [16hp](power) and [14.7Nm](torque) of peak torque.\n",
    "With [143Nm](torque) and BMW’s Shiftcam variable valve control system, there’s a huge amount of grunt almost instantly available.\n",
    "The end result is a power figure of [19.2hp](power), which is considerably higher than the 160’s [17.5hp](power). Torque, though, is actually slightly lower, at [14.2Nm](torque), compared to the 160’s [14.73Nm](torque).\n",
    "The Jupiter uses the third [125cc](capacity) engine in TVS’ stable, and this is the most basic of the lot, with a two-valve head. Nevertheless, its output figures of [8.2hp](power) and [10.5Nm](torque) are par for the segment.\n",
    "This mode is nicely usable in the dirt and it will be good for less experienced riders who might find the thought of the KTM’s [43hp](power) and [37Nm](torque) of torque a little intimidating off-road.\n",
    "third [115cc](capacity) engine [7hp](power) or [5.2kw](power) and [9Nm](torque)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d795f225-40d6-4943-91ee-8a647b529831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are all the tags and ids mapped both ways:\n",
      "{0: 'O', 1: 'B-capacity', 2: 'B-power', 3: 'B-torque', 4: 'I-power'}\n",
      "{'O': 0, 'B-capacity': 1, 'B-power': 2, 'B-torque': 3, 'I-power': 4}\n",
      "Number of tokens matching the \"B capacity\" tag:  6\n",
      "Number of tokens matching the \"B power\" tag:  13\n",
      "Number of tokens matching the \"B torque\" tag:  11\n",
      "Number of tokens matching the \"I power\" tag:  1\n"
     ]
    }
   ],
   "source": [
    "all_txt = NERDataMaker(train_text.split(\"\\n\"))\n",
    "\n",
    "B_capacity_list = []\n",
    "B_power_list = []\n",
    "B_torque_list = []\n",
    "I_power_list = []\n",
    "\n",
    "label_names = all_txt.unique_entities\n",
    "print(\"Here are all the tags and ids mapped both ways:\")\n",
    "print(all_txt.id2label)\n",
    "print(all_txt.label2id)\n",
    "for n in range(len(all_txt)):\n",
    "    [B_capacity_list.append(all_txt[n]['tokens'][all_txt[n]['ner_tags'].index(i)]) for i in all_txt[n]['ner_tags'] if i == 1]\n",
    "    [B_power_list.append(all_txt[n]['tokens'][all_txt[n]['ner_tags'].index(i)]) for i in all_txt[n]['ner_tags'] if i == 2]\n",
    "    [B_torque_list.append(all_txt[n]['tokens'][all_txt[n]['ner_tags'].index(i)]) for i in all_txt[n]['ner_tags'] if i == 3]\n",
    "    [I_power_list.append(all_txt[n]['tokens'][all_txt[n]['ner_tags'].index(i)]) for i in all_txt[n]['ner_tags'] if i == 4]\n",
    "\n",
    "print('Number of tokens matching the \"B capacity\" tag: ', len(B_capacity_list))\n",
    "print('Number of tokens matching the \"B power\" tag: ', len(B_power_list))\n",
    "print('Number of tokens matching the \"B torque\" tag: ', len(B_torque_list))\n",
    "print('Number of tokens matching the \"I power\" tag: ', len(I_power_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41429da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of examples in dataset (excluding the two blank lines at the beginning and the end):  12\n",
      "##################################################\n",
      "Here is a sample sentence, along with the tags used for training:\n",
      "The [286cc](capacity), 4 valve liquid-cooled engine architecture is the same as before, but the engine is now BS6 compliant. Power is now up by [0.6hp](power) for a total of [31.1 horsepower](power), although this is now produced 1,500rpm higher at 9,000rpm.\n",
      "##################################################\n",
      "These are all the NER tags and tokens in a sample sentence:\n",
      "{'id': 1, 'ner_tags': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['The', '286cc', '4', 'valve', 'liquid-cooled', 'engine', 'architecture', 'is', 'the', 'same', 'as', 'before,', 'but', 'the', 'engine', 'is', 'now', 'BS6', 'compliant.', 'Power', 'is', 'now', 'up', 'by', '0.6hp', 'for', 'a', 'total', 'of', '31.1', 'horsepower', 'although', 'this', 'is', 'now', 'produced', '1,500rpm', 'higher', 'at', '9,000rpm.']}\n",
      "##################################################\n",
      "These are the only tokens that have an NER tag, along with their NER tag and label\n",
      "286cc 1 B-capacity\n",
      "0.6hp 2 B-power\n",
      "0.6hp 2 B-power\n",
      "horsepower 4 I-power\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total # of examples in dataset (excluding the two blank lines at the beginning and the end): \", len(all_txt)-2)\n",
    "print('#'*50)\n",
    "print(\"Here is a sample sentence, along with the tags used for training:\")\n",
    "print(train_text.split(\"\\n\")[1])\n",
    "print('#'*50)\n",
    "print(\"After pre-processing the same sample sentence, it is converted to a dictionary of NER tags and tokens:\")\n",
    "print(all_txt[1])\n",
    "print('#'*50)\n",
    "print(\"These are the only tokens that have an NER tag, along with their NER tag and label\")\n",
    "[print(all_txt[1]['tokens'][all_txt[1]['ner_tags'].index(i)], i, all_txt.id2label[i]) for i in all_txt[1]['ner_tags'] if i != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91095aea-cd9c-4a4f-b6ae-4cc2c3ef971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of examples in dataset (excluding the two blank lines at the beginning and the end):  12\n",
      "Here is a sample sentence, along with the tags used for training:\n",
      "The [286cc](capacity), 4 valve liquid-cooled engine architecture is the same as before, but the engine is now BS6 compliant. Power is now up by [0.6hp](power) for a total of [31.1 horsepower](power), although this is now produced 1,500rpm higher at 9,000rpm.\n",
      "These are all the NER tags and tokens in a sample sentence:\n",
      "{'id': 1, 'ner_tags': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'tokens': ['The', '286cc', '4', 'valve', 'liquid-cooled', 'engine', 'architecture', 'is', 'the', 'same', 'as', 'before,', 'but', 'the', 'engine', 'is', 'now', 'BS6', 'compliant.', 'Power', 'is', 'now', 'up', 'by', '0.6hp', 'for', 'a', 'total', 'of', '31.1', 'horsepower', 'although', 'this', 'is', 'now', 'produced', '1,500rpm', 'higher', 'at', '9,000rpm.']}\n",
      "These are the only tokens that have an NER tag, along with their NER tag and label\n",
      "286cc 1 B-capacity\n",
      "0.6hp 2 B-power\n",
      "0.6hp 2 B-power\n",
      "horsepower 4 I-power\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total # of examples in dataset (excluding the two blank lines at the beginning and the end): \", len(all_txt)-2)\n",
    "print(\"Here is a sample sentence, along with the tags used for training:\")\n",
    "print(train_text.split(\"\\n\")[1])\n",
    "print(\"These are all the NER tags and tokens in a sample sentence:\")\n",
    "print(all_txt[1])\n",
    "print(\"These are the only tokens that have an NER tag, along with their NER tag and label\")\n",
    "[print(all_txt[1]['tokens'][all_txt[1]['ner_tags'].index(i)], i, all_txt.id2label[i]) for i in all_txt[1]['ner_tags'] if i != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82597c",
   "metadata": {},
   "source": [
    "### Credits, sources and references:  \n",
    "As seen in the sample sentence above, the tags are directly applied on a sentence in the training dataset. This Rasa like approach is much simpler than the error prone effort of directly creating the key value pair 'ner_tags'. Concept and code for this is from   \n",
    "https://sanjayasubedi.com.np/deeplearning/training-ner-with-huggingface-transformer/  \n",
    "https://rasa.com/docs/rasa/training-data-format  \n",
    "For many other ideas, please refer  \n",
    "https://huggingface.co/course/chapter7/2?fw=pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8430b94-f1f8-429c-b13b-9fe4fad3d79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples in train = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 73.22ba/s]\n"
     ]
    }
   ],
   "source": [
    "dm = NERDataMaker(train_text.split(\"\\n\")[:10])\n",
    "print(f\"total examples in train = {len(dm)}\")\n",
    "train_ds = dm.as_hf_dataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f87613ee-1160-42c4-9458-234eb30d9dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples in validation = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 175.38ba/s]\n"
     ]
    }
   ],
   "source": [
    "dm_val = NERDataMaker(train_text.split(\"\\n\")[10:])\n",
    "print(f\"total examples in validation = {len(dm_val)}\")\n",
    "val_ds = dm_val.as_hf_dataset(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2501f641-c4f4-4e5d-8af6-dacabeee74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "model = AutoModelForTokenClassification.from_pretrained(checkpoint, num_labels=len(dm.unique_entities), id2label=dm.id2label, label2id=dm.label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff4fd39c-0303-4dc2-ba48-c708dcda007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 118.70ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.51ba/s]\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 90\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3037259578704834, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.8846153846153846, 'eval_runtime': 0.2236, 'eval_samples_per_second': 17.892, 'eval_steps_per_second': 8.946, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0504786968231201, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.8846153846153846, 'eval_runtime': 0.1475, 'eval_samples_per_second': 27.125, 'eval_steps_per_second': 13.563, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9172098636627197, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.8846153846153846, 'eval_runtime': 0.1594, 'eval_samples_per_second': 25.091, 'eval_steps_per_second': 12.546, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9042731523513794, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.8846153846153846, 'eval_runtime': 0.1494, 'eval_samples_per_second': 26.772, 'eval_steps_per_second': 13.386, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8293474912643433, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.8846153846153846, 'eval_runtime': 0.1678, 'eval_samples_per_second': 23.837, 'eval_steps_per_second': 11.919, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6735749244689941, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.8846153846153846, 'eval_runtime': 0.1723, 'eval_samples_per_second': 23.218, 'eval_steps_per_second': 11.609, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.537849485874176, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.8846153846153846, 'eval_runtime': 0.1498, 'eval_samples_per_second': 26.703, 'eval_steps_per_second': 13.352, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44580450654029846, 'eval_precision': 1.0, 'eval_recall': 0.1111111111111111, 'eval_f1': 0.19999999999999998, 'eval_accuracy': 0.8974358974358975, 'eval_runtime': 0.3156, 'eval_samples_per_second': 12.674, 'eval_steps_per_second': 6.337, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38221412897109985, 'eval_precision': 1.0, 'eval_recall': 0.4444444444444444, 'eval_f1': 0.6153846153846153, 'eval_accuracy': 0.9358974358974359, 'eval_runtime': 0.1671, 'eval_samples_per_second': 23.942, 'eval_steps_per_second': 11.971, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33923375606536865, 'eval_precision': 1.0, 'eval_recall': 0.6666666666666666, 'eval_f1': 0.8, 'eval_accuracy': 0.9615384615384616, 'eval_runtime': 0.3177, 'eval_samples_per_second': 12.592, 'eval_steps_per_second': 6.296, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31548207998275757, 'eval_precision': 0.8571428571428571, 'eval_recall': 0.6666666666666666, 'eval_f1': 0.75, 'eval_accuracy': 0.9615384615384616, 'eval_runtime': 0.2435, 'eval_samples_per_second': 16.424, 'eval_steps_per_second': 8.212, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29611659049987793, 'eval_precision': 0.75, 'eval_recall': 0.6666666666666666, 'eval_f1': 0.7058823529411765, 'eval_accuracy': 0.9615384615384616, 'eval_runtime': 0.1904, 'eval_samples_per_second': 21.003, 'eval_steps_per_second': 10.502, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27795135974884033, 'eval_precision': 0.7777777777777778, 'eval_recall': 0.7777777777777778, 'eval_f1': 0.7777777777777778, 'eval_accuracy': 0.9743589743589743, 'eval_runtime': 0.1652, 'eval_samples_per_second': 24.207, 'eval_steps_per_second': 12.104, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2576477527618408, 'eval_precision': 0.7777777777777778, 'eval_recall': 0.7777777777777778, 'eval_f1': 0.7777777777777778, 'eval_accuracy': 0.9743589743589743, 'eval_runtime': 0.1457, 'eval_samples_per_second': 27.457, 'eval_steps_per_second': 13.729, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23712733387947083, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1595, 'eval_samples_per_second': 25.078, 'eval_steps_per_second': 12.539, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2169295847415924, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.2732, 'eval_samples_per_second': 14.641, 'eval_steps_per_second': 7.321, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2013443112373352, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1925, 'eval_samples_per_second': 20.778, 'eval_steps_per_second': 10.389, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19037340581417084, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.2265, 'eval_samples_per_second': 17.662, 'eval_steps_per_second': 8.831, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18220141530036926, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1756, 'eval_samples_per_second': 22.783, 'eval_steps_per_second': 11.392, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1756155788898468, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1554, 'eval_samples_per_second': 25.737, 'eval_steps_per_second': 12.869, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1703716516494751, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1547, 'eval_samples_per_second': 25.862, 'eval_steps_per_second': 12.931, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1666470319032669, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1567, 'eval_samples_per_second': 25.532, 'eval_steps_per_second': 12.766, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16377149522304535, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.2257, 'eval_samples_per_second': 17.725, 'eval_steps_per_second': 8.863, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16151002049446106, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.173, 'eval_samples_per_second': 23.12, 'eval_steps_per_second': 11.56, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15929174423217773, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1724, 'eval_samples_per_second': 23.199, 'eval_steps_per_second': 11.6, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15766137838363647, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1772, 'eval_samples_per_second': 22.578, 'eval_steps_per_second': 11.289, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15634822845458984, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.2801, 'eval_samples_per_second': 14.28, 'eval_steps_per_second': 7.14, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15544500946998596, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.2065, 'eval_samples_per_second': 19.374, 'eval_steps_per_second': 9.687, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15497231483459473, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1682, 'eval_samples_per_second': 23.786, 'eval_steps_per_second': 11.893, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 4\n",
      "  Batch size = 2\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15478608012199402, 'eval_precision': 0.8888888888888888, 'eval_recall': 0.8888888888888888, 'eval_f1': 0.8888888888888888, 'eval_accuracy': 0.9871794871794872, 'eval_runtime': 0.1653, 'eval_samples_per_second': 24.193, 'eval_steps_per_second': 12.097, 'epoch': 30.0}\n",
      "{'train_runtime': 127.2085, 'train_samples_per_second': 2.358, 'train_steps_per_second': 0.707, 'train_loss': 0.19146686130099827, 'epoch': 30.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=90, training_loss=0.19146686130099827, metrics={'train_runtime': 127.2085, 'train_samples_per_second': 2.358, 'train_steps_per_second': 0.707, 'train_loss': 0.19146686130099827, 'epoch': 30.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "train_ds = dm.as_hf_dataset(tokenizer=tokenizer)\n",
    "val_ds = dm_val.as_hf_dataset(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba26dbb",
   "metadata": {},
   "source": [
    "### Saving the trained model (neural network architecture and all parameter values) locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6afce411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to data_dir/customNER20220919.pt\n",
      "Configuration saved in data_dir/customNER20220919.pt/config.json\n",
      "Model weights saved in data_dir/customNER20220919.pt/pytorch_model.bin\n",
      "tokenizer config file saved in data_dir/customNER20220919.pt/tokenizer_config.json\n",
      "Special tokens file saved in data_dir/customNER20220919.pt/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/bala/Documents/Learning'\n",
    "trainer.save_model(\"data_dir/customNER20220919.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aa8586",
   "metadata": {},
   "source": [
    "### Running a test with a sample sentence with no entity tags  \n",
    "(Note the true labels are all default values and that the predictions are exactly what we'd expect to see)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c38f270-30f4-44dd-a657-a4ff6e7c16f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total examples in test = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 97.59ba/s]\n",
      "The following columns in the test set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 2\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the test set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 2\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "The following columns in the test set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: id, tokens, ner_tags. If id, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 3\n",
      "  Batch size = 2\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bala/anaconda3/envs/pyTorch/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>164.9cc.</td>\n",
       "      <td>O</td>\n",
       "      <td>B-capacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>19.2hp,</td>\n",
       "      <td>O</td>\n",
       "      <td>B-power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>17.5hp.</td>\n",
       "      <td>O</td>\n",
       "      <td>B-power</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>14.2Nm,</td>\n",
       "      <td>O</td>\n",
       "      <td>B-torque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>14.73Nm.</td>\n",
       "      <td>O</td>\n",
       "      <td>B-torque</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tokens true_labels predictions\n",
       "7   164.9cc.           O  B-capacity\n",
       "68   19.2hp,           O     B-power\n",
       "76   17.5hp.           O     B-power\n",
       "84   14.2Nm,           O    B-torque\n",
       "89  14.73Nm.           O    B-torque"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"\"\"\n",
    "Unsurprisingly, this bike’s displacement is a neat 164.9cc. But this isn’t just a simple boring and stroking job from TVS – there are also significant changes to the cylinder head, with larger valves and ports, and different cam profiles. The piston is also different from the 160, not just in the sense that it’s larger, but also in its shape. The end result is a power figure of 19.2hp, which is considerably higher than the 160’s 17.5hp. Torque, though, is actually slightly lower, at 14.2Nm, compared to the 160’s 14.73Nm. What’s telling is the fact that the RP makes its peak figures a good deal higher up the rev range than the RTR 160 4V.\n",
    "\"\"\"\n",
    "\n",
    "dm_test = NERDataMaker(test_text.split(\"\\n\"))\n",
    "print(f\"total examples in test = {len(dm_test)}\")\n",
    "test_ds = dm_test.as_hf_dataset(tokenizer=tokenizer)\n",
    "\n",
    "answer = pd.DataFrame()\n",
    "answer['tokens'] = postprocess(test_ds)[0]['tokens'][1]\n",
    "answer['true_labels'] = postprocess(test_ds)[1]['true_labels'][1]\n",
    "answer['predictions'] = postprocess(test_ds)[2]['prediction_out'][1]\n",
    "answer[answer['predictions'] != 'O']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586386e",
   "metadata": {},
   "source": [
    "### Inference using a simple pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd58b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_checkpoint = \"data_dir/customNER20220919.pt\" #loading the trained/ fine-tuned model from local\n",
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94791dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'capacity',\n",
       "  'score': 0.644535,\n",
       "  'word': '199',\n",
       "  'start': 73,\n",
       "  'end': 76},\n",
       " {'entity_group': 'power',\n",
       "  'score': 0.8060533,\n",
       "  'word': '1',\n",
       "  'start': 127,\n",
       "  'end': 128},\n",
       " {'entity_group': 'torque',\n",
       "  'score': 0.8604862,\n",
       "  'word': '1',\n",
       "  'start': 135,\n",
       "  'end': 136}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier(\"As the name suggests, this bike now gets a 4-valve cylinder head for its 199.6cc engine. Power and torque are both up by about 1hp and 1Nm each, without any changes in the rpms they’re produced at. \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pyTorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb36900a64489a334b85f69b0bd0694b6a7e151e9f8e1439a7538ecb3bec0d82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
